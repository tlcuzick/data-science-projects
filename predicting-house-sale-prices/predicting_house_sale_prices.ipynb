{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predicting_house_sale_prices.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXhT3D/np6Qv08mxQjEdZL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlcuzick/data-science-projects/blob/main/predicting-house-sale-prices/predicting_house_sale_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc2isCclVCPc"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj_RVSaoVUx3"
      },
      "source": [
        "# **Feature Engineering**\r\n",
        "\r\n",
        "* Drop columns where more than 25% of values are null\r\n",
        "* Drop all **text** columns with any null values\r\n",
        "* Fill in missing numerical values with the overall means from their parent columns\r\n",
        "* Add \"years_sold\" and \"years_since_remod\" features\r\n",
        "* Drop rows with negative values for \"years_sold\" and \"years_since_remod\"\r\n",
        "* Drop columns that either arent't useful for ML (\"PID\" for example) or leak info we wouldn't know about until the sale occurred (such as \"Sale Condition\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bp-RuZkVfS8"
      },
      "source": [
        "def transform_features(data):\r\n",
        "    num_missing = data.isnull().sum()\r\n",
        "    max_missing = data.shape[0] / 4\r\n",
        "    cols_to_drop = num_missing[num_missing > max_missing].index\r\n",
        "    data = data.drop(cols_to_drop, axis=1)\r\n",
        "    \r\n",
        "    num_missing_txt = data.select_dtypes(include=['object']).isnull().sum()\r\n",
        "    cols_to_drop_2 = num_missing_txt[num_missing_txt > 0].index\r\n",
        "    data = data.drop(cols_to_drop_2, axis=1)\r\n",
        "    \r\n",
        "    num_missing_numeric = data.select_dtypes(include=['integer', 'float']).isnull().sum()\r\n",
        "    cols_to_fix = num_missing_numeric[num_missing_numeric > 0].index\r\n",
        "    means = data[cols_to_fix].mean()\r\n",
        "    data = data.fillna(means)\r\n",
        "    \r\n",
        "    years_sold = data['Yr Sold'] - data['Year Built']\r\n",
        "    years_since_remod = data['Yr Sold'] - data['Year Remod/Add']\r\n",
        "\r\n",
        "    data['Years Before Sale'] = years_sold\r\n",
        "    data['Years Since Remod'] = years_since_remod\r\n",
        "\r\n",
        "    data = data.drop([2180, 1702, 2181], axis=0)\r\n",
        "    data = data.drop(['Year Built', 'Year Remod/Add'], axis=1)\r\n",
        "\r\n",
        "    data = data.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\", \"PID\", \"Order\"], axis=1)\r\n",
        "    \r\n",
        "    return data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvQsXaSOVopF"
      },
      "source": [
        "# **Feature Selection**\r\n",
        "\r\n",
        "* Remove columns with a correlation threshold less than 0.3\r\n",
        "* Remove categorical features with more than 10 unique values\r\n",
        "* Create \"dummy\" columns for categorical features with 10 or fewer unique values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Nl9njQVuei"
      },
      "source": [
        "def count_unique_vals(col):\r\n",
        "    return len(col.value_counts())\r\n",
        "\r\n",
        "def select_features(data, corr_threshold=0.3, uniq_threshold =10):\r\n",
        "    numerical_transformed_features = data.select_dtypes(include=['integer','float'])\r\n",
        "    \r\n",
        "    sale_price_corr = numerical_transformed_features.corr()['SalePrice'].abs()\r\n",
        "    \r\n",
        "    cols_to_drop = sale_price_corr[sale_price_corr < corr_threshold].index\r\n",
        "    \r\n",
        "    data = data.drop(cols_to_drop, axis=1)\r\n",
        "    \r\n",
        "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \r\n",
        "                        \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \r\n",
        "                        \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \r\n",
        "                        \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\r\n",
        "    nom_cols_to_transform = []\r\n",
        "\r\n",
        "    for col in nominal_features:\r\n",
        "        if col in data.columns:\r\n",
        "            nom_cols_to_transform.append(col)\r\n",
        "            \r\n",
        "    unique_val_counts = data[nom_cols_to_transform].apply(count_unique_vals)\r\n",
        "    nonunique_cols = unique_val_counts[unique_val_counts > 10].index\r\n",
        "    \r\n",
        "    data.drop(nonunique_cols, axis=1)\r\n",
        "    \r\n",
        "    text_cols = data.select_dtypes(include = ['object']).columns\r\n",
        "\r\n",
        "    for col in text_cols:\r\n",
        "        data[col] = data[col].astype('category')\r\n",
        "        \r\n",
        "    dummy_cols = pd.get_dummies(data.select_dtypes(include = ['category']))\r\n",
        "\r\n",
        "    data = pd.concat([data, dummy_cols], axis=1)\r\n",
        "    \r\n",
        "    return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWgqxf8cV7zm"
      },
      "source": [
        "# **Train and Test the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVGQD_dYWFhk"
      },
      "source": [
        "def train_and_test(data, k=0):\r\n",
        "    numeric_cols = data.select_dtypes(include=['integer', 'float'])\r\n",
        "    features = numeric_cols.columns.drop('SalePrice')\r\n",
        "\r\n",
        "    lr = linear_model.LinearRegression()\r\n",
        "    \r\n",
        "    if k == 0:\r\n",
        "        train = data[:1460]\r\n",
        "        test = data[1460:]\r\n",
        "        \r\n",
        "        lr.fit(train[features], train['SalePrice'])    \r\n",
        "        predicted_sale_prices = lr.predict(test[features])\r\n",
        "\r\n",
        "        mse = mean_squared_error(test['SalePrice'], predicted_sale_prices)\r\n",
        "        rmse = mse ** (1/2)\r\n",
        "\r\n",
        "        return rmse\r\n",
        "    \r\n",
        "    if k == 1:\r\n",
        "        shuffled_data = data.sample(frac=1, )\r\n",
        "        train = data[:1460]\r\n",
        "        test = data[1460:]\r\n",
        "        \r\n",
        "        lr.fit(train[features], train[\"SalePrice\"])\r\n",
        "        predictions_one = lr.predict(test[features])        \r\n",
        "        \r\n",
        "        mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\r\n",
        "        rmse_one = mse_one ** (1/2)\r\n",
        "        \r\n",
        "        lr.fit(test[features], test[\"SalePrice\"])\r\n",
        "        predictions_two = lr.predict(train[features])        \r\n",
        "       \r\n",
        "        mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\r\n",
        "        rmse_two = mse_two ** (1/2)\r\n",
        "        \r\n",
        "        avg_rmse = np.mean([rmse_one, rmse_two])\r\n",
        "        print('RMSE one: {}'.format(rmse_one))\r\n",
        "        print('RMSE two: {}'.format(rmse_two))\r\n",
        "        return avg_rmse\r\n",
        "    else:\r\n",
        "        kf = KFold(n_splits=k, shuffle=True)\r\n",
        "        rmse_values = []\r\n",
        "        for train_index, test_index, in kf.split(data):\r\n",
        "            train = data.iloc[train_index]\r\n",
        "            test = data.iloc[test_index]\r\n",
        "            lr.fit(train[features], train[\"SalePrice\"])\r\n",
        "            predictions = lr.predict(test[features])\r\n",
        "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\r\n",
        "            rmse = mse  ** (1/2)\r\n",
        "            rmse_values.append(rmse)\r\n",
        "        avg_rmse = np.mean(rmse_values)\r\n",
        "        return avg_rmse"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY2E3GJQWLbz",
        "outputId": "dcce7051-4bb3-47a2-ed28-c88e35a7622b"
      },
      "source": [
        "data = pd.read_csv('AmesHousing.tsv', delimiter=\"\\t\")\r\n",
        "transformed_features = transform_features(data)\r\n",
        "selected_features = select_features(transformed_features)\r\n",
        "rmse = train_and_test(selected_features)\r\n",
        "print(rmse)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32005.636765137042\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
