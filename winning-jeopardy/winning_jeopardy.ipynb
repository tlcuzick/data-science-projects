{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "winning_jeopardy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPz76xZrhwEgekAwu/dm2Ep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tlcuzick/data-science-projects/blob/main/winning-jeopardy/winning_jeopardy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcGxgzcGeBzJ"
      },
      "source": [
        "import pandas as pd\r\n",
        "import string\r\n",
        "from scipy.stats import chisquare"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0RBKGiteUkw"
      },
      "source": [
        "jeopardy = pd.read_csv('jeopardy.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVLFkN26eXoM",
        "outputId": "a0814ff7-bb67-4c6c-9103-24a6515264f2"
      },
      "source": [
        "print(jeopardy.head(5))\r\n",
        "print(jeopardy.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Show Number  ...      Answer\n",
            "0         4680  ...  Copernicus\n",
            "1         4680  ...  Jim Thorpe\n",
            "2         4680  ...     Arizona\n",
            "3         4680  ...  McDonald's\n",
            "4         4680  ...  John Adams\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
            "       ' Question', ' Answer'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKsJL0cwebv-"
      },
      "source": [
        "jeopardy.rename(columns=lambda x: x.replace(' ',''),inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGQVajkFekcM"
      },
      "source": [
        "def normalize_text(text):\r\n",
        "    punc = string.punctuation\r\n",
        "    new_text = ''\r\n",
        "    for l in text:\r\n",
        "        if not(l in punc):\r\n",
        "            new_text = new_text + l\r\n",
        "    return new_text.lower()\r\n",
        "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\r\n",
        "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgUMZA1ZeoMP"
      },
      "source": [
        "def normalize_dollars(text):\r\n",
        "    punc = string.punctuation\r\n",
        "    new_text = ''\r\n",
        "    for l in text:\r\n",
        "        if not(l in punc):\r\n",
        "            new_text = new_text + l\r\n",
        "    try:\r\n",
        "        num = int(new_text)\r\n",
        "    except ValueError:\r\n",
        "        num = 0\r\n",
        "    return num\r\n",
        "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_dollars)\r\n",
        "jeopardy['AirDate'] = jeopardy['AirDate'].apply(pd.to_datetime)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INOc-bv6eqff"
      },
      "source": [
        "def avg_matches(row):\r\n",
        "    split_answer = row['clean_answer'].split(' ')\r\n",
        "    if 'the' in split_answer:\r\n",
        "        split_answer.remove('the')\r\n",
        "    if len(split_answer) == 0:\r\n",
        "        return 0\r\n",
        "    split_question = row['clean_question'].split(' ')\r\n",
        "    match_count = 0\r\n",
        "    for a in split_answer:\r\n",
        "        if a in split_question:\r\n",
        "            match_count += 1\r\n",
        "    return match_count / len(split_answer)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSIsIjJbet2V"
      },
      "source": [
        "jeopardy['answer_in_question'] = jeopardy.apply(avg_matches,axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4fVT39Se2ES",
        "outputId": "26adf6ae-793c-4552-ff36-a8a7fb190171"
      },
      "source": [
        "print(jeopardy['answer_in_question'].mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.060352773854699004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEv8bzsIe7oj"
      },
      "source": [
        "Since 6% of the words in jeopardy answers also occurred in the corresponding question, consciously giving more consideration to potential answers that include words from the question seems like one potentially effective strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl3EzC5ze9TF",
        "outputId": "da0061d4-f65f-433a-afad-6d4d58afe508"
      },
      "source": [
        "question_overlap = []\r\n",
        "terms_used = set()\r\n",
        "for index, row in jeopardy.iterrows():\r\n",
        "    split_question = row['clean_question'].split(' ')\r\n",
        "    split_question = [n for n in split_question if len(n) >= 6]\r\n",
        "    match_count = 0\r\n",
        "    \r\n",
        "    for q in split_question:\r\n",
        "        if q in terms_used:\r\n",
        "            match_count += 1\r\n",
        "        terms_used.add(q)\r\n",
        "    question_overlap.append(match_count)\r\n",
        "    \r\n",
        "question_overlap = pd.Series(question_overlap)\r\n",
        "jeopardy['question_overlap'] = question_overlap\r\n",
        "print(jeopardy['question_overlap'].mean())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.073953697684884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssciIbKOfFUb"
      },
      "source": [
        "Since an average of three words (with 6 or more characters) per question were repeated from previous questions, it seems reasonable to conclude that questions are occasionally, at least to some extent, being recycled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTlzkKo6fGht"
      },
      "source": [
        "def high_low(row):\r\n",
        "    if row['clean_value'] > 800:\r\n",
        "        value = 1\r\n",
        "    else:\r\n",
        "        value = 0\r\n",
        "    return value\r\n",
        "jeopardy['high_value'] = jeopardy.apply(high_low, axis=1)\r\n",
        "\r\n",
        "def high_low_count(word):\r\n",
        "    low_count = 0\r\n",
        "    high_count = 0\r\n",
        "    for index, row in jeopardy.iterrows():\r\n",
        "        split_question = row['clean_question'].split(' ')\r\n",
        "        if word in split_question:\r\n",
        "            if row['high_value'] == 1:\r\n",
        "                high_count += 1\r\n",
        "            else:\r\n",
        "                low_count += 1\r\n",
        "    return high_count, low_count\r\n",
        "\r\n",
        "observed_expected = []\r\n",
        "terms_used = list(terms_used)\r\n",
        "comparison_terms = terms_used[0:5]\r\n",
        "\r\n",
        "for t in comparison_terms:\r\n",
        "    observed_expected.append(high_low_count(t))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqldBnSFfONy",
        "outputId": "d966a606-ae5b-473b-fc52-d09cc1fa7aaf"
      },
      "source": [
        "high_value_count = sum(jeopardy['high_value'])\r\n",
        "low_value_count = jeopardy.shape[0] - high_value_count\r\n",
        "chi_squared = []\r\n",
        "\r\n",
        "for l in observed_expected:\r\n",
        "    total = l[0] + l[1]\r\n",
        "    total_prop = total / jeopardy.shape[0]\r\n",
        "    high_value_expected = total_prop * high_value_count\r\n",
        "    low_value_expected = total_prop * low_value_count\r\n",
        "    chisq, pval = chisquare(l,[high_value_expected,low_value_expected])\r\n",
        "    chi_squared.append([chisq, pval])\r\n",
        "print(chi_squared)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.487792117195675, 0.11473257634454047], [0.401962846126884, 0.5260772985705469], [0.401962846126884, 0.5260772985705469], [0.401962846126884, 0.5260772985705469], [0.401962846126884, 0.5260772985705469]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sky6JvyfWst"
      },
      "source": [
        "Based on the limited sample of words I reviewed, there appears to be correlation in some cases (p-value around 0.1), but not enough to be considered statistically significant with a threshold of 0.05.\r\n",
        "\r\n",
        "It may prove helpful to analyze words which appear in questions with more frequency."
      ]
    }
  ]
}
